import os
import json

try:
    from dotenv import load_dotenv  # type: ignore
    load_dotenv()
except Exception:
    ## dotenv not installed or .env not present — continue, values may be in the environment
    pass


## ---------------------------
## General / Telegram
## ---------------------------
TG_POLLING_TIMEOUT = int(os.getenv("TG_POLLING_TIMEOUT", "60"))
TG_SOCK_CONNECT_TIMEOUT = float(os.getenv("TG_SOCK_CONNECT_TIMEOUT", "10"))
TG_SOCK_READ_TIMEOUT = float(os.getenv("TG_SOCK_READ_TIMEOUT", "600"))
## Telegram bot token (required)
_TELEGRAM_BOT_TOKEN_RAW = os.getenv("TELEGRAM_BOT_TOKEN", "")
## sanitize token
TELEGRAM_BOT_TOKEN = _TELEGRAM_BOT_TOKEN_RAW.strip().strip('"').strip("'").lstrip("\ufeff")


## Parse mode used when creating Bot in main.py (kept for reference)
DEFAULT_PARSE_MODE = os.getenv("DEFAULT_PARSE_MODE", "HTML")


## ---------------------------
## Database (MySQL / aiomysql)
## ---------------------------
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = int(os.getenv("DB_PORT", 3306))
DB_NAME = os.getenv("DB_NAME", "korneslov")
DB_USER = os.getenv("DB_USER", "korneslov")
DB_PASS = os.getenv("DB_PASS", "")

## Pool size for aiomysql
DB_POOL_MIN_SIZE = int(os.getenv("DB_POOL_MIN_SIZE", 1))
DB_POOL_MAX_SIZE = int(os.getenv("DB_POOL_MAX_SIZE", 10))


## ---------------------------
## Payment / TG payment providers
## ---------------------------
## Telegram invoice photo (optional)
TGPAYMENT_PHOTO = os.getenv("TGPAYMENT_PHOTO", "")

## Static providers list — keep the original structure exactly as requested.
## These providers are used in different deployments; do NOT remove or transform this list.
TGPAYMENT_PROVIDERS = [
    {
        "name": "Redsys",
        "provider_token": "2051251535:TEST:OTk5MDA4ODgxLTAwNQ",
        "currency": "EUR",
        "country": "ES",
        "exchange_rate": 0.98,
    },
    {
        "name": "YooKassa",
        "provider_token": "381764678:TEST:143626",
        "currency": "RUB",
        "country": "RU",
        "exchange_rate": 0.1,
    },
    {
        "name": "Portmone",
        "provider_token": "1661751239:TEST:UOis-G51K-pl7k-53zV",
        "currency": "UAH",
        "country": "UA",
        "exchange_rate": 0.2,
    },
]

## Internal prices for requests in "koreshoks" (internal unit)
TGPAYMENT_REQUEST_PRICES = {
    "light": int(os.getenv("PRICE_LIGHT", 1)),
    "smart": int(os.getenv("PRICE_SMART", 2)),
    "hard": int(os.getenv("PRICE_HARD", 3)),
}


## ---------------------------
## AI providers (OpenAI / Gemini) and model selection
## ---------------------------
## Select provider via environment: "openai" or "gemini" (case-insensitive)
AI_PROVIDER = os.getenv("AI_PROVIDER", "openai").lower()

## Gemini config
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.5-flash")
GEMINI_MAX_OUTPUT_TOKENS_CAP = int(os.getenv("GEMINI_MAX_OUTPUT_TOKENS_CAP", "12000"))
GEMINI_TEMPERATURE = float(os.getenv("GEMINI_TEMPERATURE", "0.7"))
GEMINI_USE_STREAMING = (os.getenv("GEMINI_USE_STREAMING", "false").lower() in ("1", "true", "yes"))

## OpenAI config
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-5")
OPENAI_MODEL_PARAMS = {
    "gpt-4o-mini": {"max_tokens": 3000, "temperature": 0.7},
    "gpt-4o": {"max_tokens": 3000, "temperature": 0.7},
    "gpt-5": {},
}


## ---------------------------
## Unified accessors and helpers
## ---------------------------
def get_model_and_params():
    """
    Return a tuple (model_name, params_dict) depending on currently selected AI_PROVIDER.
    Params are provider-agnostic (e.g. max_tokens, temperature). Service wrapper
    (openai_srv / gemini_srv) must adapt these keys as required.
    """
    provider = (AI_PROVIDER or "openai").lower()

    if provider == "openai":
        model = OPENAI_MODEL
        params = OPENAI_MODEL_PARAMS.get(model, {}).copy()
        return model, params

    if provider == "gemini":
        model = GEMINI_MODEL
        params = GEMINI_MODEL_PARAMS.get(model, {}).copy()
        return model, params

    ## Unknown provider: fallback to OpenAI defaults
    model = OPENAI_MODEL
    params = OPENAI_MODEL_PARAMS.get(model, {}).copy()
    return model, params


## ---------------------------
## Misc / feature flags / debug
## ---------------------------
## Keep DUMMY_TEXT flag for offline dev/test flows
DUMMY_TEXT = os.getenv("DUMMY_TEXT", "0").lower() in ("1", "true", "yes")

## Optional flag to enable saving of raw requests/responses for debugging
SAVE_RAW_AI_EXCHANGES = os.getenv("SAVE_RAW_AI_EXCHANGES", "0").lower() in ("1", "true", "yes")

